{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import cv2\n",
    "import os \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import random \n",
    "import time\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BEF_RES = 256\n",
    "N_RES = 256 \n",
    "# N_CLASSES = 143 \n",
    "N_BATCH = 32 \n",
    "\n",
    "input_shape = (N_RES, N_RES, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Dropbox/2. WORK/SNUH/Child Skin Disease\\\\Total_Dataset'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATH = 'C:/Users/user/Desktop/Child Skin Disease'\n",
    "PATH = \"D:/Dropbox/2. WORK/SNUH/Child Skin Disease\"\n",
    "dataset = os.path.join(PATH, 'Total_Dataset')\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & test set\n",
    "limit_num = 0\n",
    "base_num = 100\n",
    "train_dict = {}\n",
    "test_dict = {} \n",
    "\n",
    "for i in range(6):\n",
    "    files = os.listdir(os.path.join(dataset, f'H{i}'))\n",
    "    \n",
    "    for f in files: \n",
    "        imgs = glob(os.path.join(dataset, f'H{i}', f) + '/*.jpg')\n",
    "        \n",
    "        if len(imgs) > limit_num: \n",
    "            train_dict[f] = len(imgs)\n",
    "            \n",
    "for i in range(7, 10): \n",
    "    files = [val for val in list(train_dict.keys())]\n",
    "    \n",
    "    for f in files:\n",
    "        imgs = glob(os.path.join(dataset, f'H{i}', f) + '/*.jpg')\n",
    "        test_dict[f] = len(imgs) \n",
    "        \n",
    "\n",
    "N_CLASSES = len(train_dict)\n",
    "\n",
    "\n",
    "# train_dict, test_dict, N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57558, 51092)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = [] \n",
    "test_images = []\n",
    "\n",
    "for i in range(6):\n",
    "    for key in train_dict.keys():\n",
    "        img = glob(dataset + f'/H{str(i)}/{key}/*.jpg')\n",
    "        train_images.extend(img) \n",
    "        \n",
    "for i in range(7, 10):\n",
    "    for key in train_dict.keys():\n",
    "        img = glob(dataset + f'/H{str(i)}/{key}/*.jpg')\n",
    "        test_images.extend(img) \n",
    "        \n",
    "        \n",
    "random.shuffle(train_images)\n",
    "random.shuffle(test_images)\n",
    "        \n",
    "len(train_images), len(test_images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abscess': 0,\n",
       " 'Acanthosis nigricans': 1,\n",
       " 'Acne': 2,\n",
       " 'Acne neonatorum': 3,\n",
       " 'Acne scar integrated': 4,\n",
       " 'Acquired tufted hamangioma': 5,\n",
       " 'Alopecia areata': 6,\n",
       " 'Anetoderma': 7,\n",
       " 'Angioedema': 8,\n",
       " 'Angiofibroma': 9,\n",
       " 'Angiokeratoma': 10,\n",
       " 'Angular cheilitis': 11,\n",
       " 'Aplasia cutis, congenital': 12,\n",
       " \"Beau's lines\": 13,\n",
       " \"Becker's nevus\": 14,\n",
       " 'Blue nevus': 15,\n",
       " 'Cafe-au-lait spot': 16,\n",
       " 'Cellulitis': 17,\n",
       " 'Cheilitis': 18,\n",
       " 'Chicken pox (varicella)': 19,\n",
       " 'Childhood granulomatous periorificial dermatitis': 20,\n",
       " 'Confluent and reticulated papillomatosis': 21,\n",
       " 'Congenital Hemangioma': 22,\n",
       " 'Contact dermatitis': 23,\n",
       " 'Corn, Callus': 24,\n",
       " 'Cutaneous larva migrans': 25,\n",
       " 'Cutaneous lupus erythematosus': 26,\n",
       " 'Cutis marmorata': 27,\n",
       " 'Cutis marmorata telangiectatica congenita (CMTC)': 28,\n",
       " 'Cyst integrated': 29,\n",
       " 'Dermal Melanocytic Hamartoma': 30,\n",
       " 'Dermatofibroma': 31,\n",
       " 'Drug eruption': 32,\n",
       " 'Dyshidrotic eczema': 33,\n",
       " 'Eczema herpeticum': 34,\n",
       " 'Epidermal nevus': 35,\n",
       " 'Erythema dyschromicum perstans': 36,\n",
       " 'Erythema multiforme': 37,\n",
       " 'Erythema nodosum': 38,\n",
       " 'Fixed drug eruption': 39,\n",
       " 'Folliculitis': 40,\n",
       " 'Freckle': 41,\n",
       " 'Gianotti-Crosti Syndrome': 42,\n",
       " 'Graft Versus Host Disease': 43,\n",
       " 'Granuloma annulare': 44,\n",
       " 'Guttate psoriasis': 45,\n",
       " 'Halo nevus': 46,\n",
       " 'Hand eczema': 47,\n",
       " 'Hand, foot and mouth disease': 48,\n",
       " 'Hemangioma integrated': 49,\n",
       " 'Henoch-Schonlein purpura': 50,\n",
       " 'Herpes simplex infection': 51,\n",
       " 'Herpes zoster': 52,\n",
       " 'Ichthyosis': 53,\n",
       " 'ILVEN': 54,\n",
       " 'Impetigo': 55,\n",
       " 'Incontinentia pigmenti': 56,\n",
       " 'Infantile seborrheic dermatitis': 57,\n",
       " 'Ingrowing nail': 58,\n",
       " 'Insect bites and stings': 59,\n",
       " 'Juvenile xanthogranuloma': 60,\n",
       " 'Keloid scar': 61,\n",
       " 'Keratosis pilaris': 62,\n",
       " 'Lichen amyloidosis': 63,\n",
       " 'Lichen nitidus': 64,\n",
       " 'Lichen simplex chronicus': 65,\n",
       " 'Lichen striatus': 66,\n",
       " 'Linear scleroderma': 67,\n",
       " 'Livedo reticularis': 68,\n",
       " 'Livedoid vasculitis': 69,\n",
       " 'Localized scleroderma': 70,\n",
       " 'Lymphangioma': 71,\n",
       " 'Mastocytoma': 72,\n",
       " 'Melanocytic nevus': 73,\n",
       " 'Melanonychia': 74,\n",
       " 'Milium': 75,\n",
       " 'Molluscum contagiosum': 76,\n",
       " 'Mongolian spot': 77,\n",
       " 'Neurofibroma': 78,\n",
       " 'Neurofibromatosis': 79,\n",
       " 'Nevus anemicus': 80,\n",
       " 'Nevus comedonicus': 81,\n",
       " 'Nevus depigmentosus': 82,\n",
       " 'Nevus lipomatous superficialis': 83,\n",
       " 'Nevus of Ota': 84,\n",
       " 'Nevus sebaceus': 85,\n",
       " 'Nevus spilus': 86,\n",
       " 'Normal': 87,\n",
       " 'Nummular eczema': 88,\n",
       " 'Onychodystrophy': 89,\n",
       " 'Onycholysis': 90,\n",
       " 'Onychomycosis': 91,\n",
       " 'Palmoplantar keratoderma': 92,\n",
       " 'Paronychia': 93,\n",
       " 'Partial unilateral lentiginosis': 94,\n",
       " 'Perioral dermatitis': 95,\n",
       " 'Pigmented purpuric dermatosis': 96,\n",
       " 'Pilomatricoma': 97,\n",
       " 'Pitted keratolysis': 98,\n",
       " 'Pityriasis alba': 99,\n",
       " 'Pityriasis amiantacea': 100,\n",
       " 'Pityriasis lichenoides': 101,\n",
       " 'Pityriasis rosea': 102,\n",
       " 'Pityriasis versicolor': 103,\n",
       " 'Port-Wine stain': 104,\n",
       " 'Postinflammatory hyperpigmentation': 105,\n",
       " 'Postinflammatory hypopigmentation': 106,\n",
       " 'Progressive macular hypomelanosis': 107,\n",
       " 'Prurigo': 108,\n",
       " 'Prurigo pigmentosa': 109,\n",
       " 'Psoriasis': 110,\n",
       " 'Purpura': 111,\n",
       " 'Pyogenic granuloma': 112,\n",
       " 'Salmon patch': 113,\n",
       " 'Scabies': 114,\n",
       " 'Scar': 115,\n",
       " 'Seborrheic dermatitis': 116,\n",
       " 'Skin tag': 117,\n",
       " 'Spider angioma': 118,\n",
       " 'Staphylococcal scalded skin syndrome': 119,\n",
       " 'Steatocystoma multiplex': 120,\n",
       " 'Striae distensae': 121,\n",
       " 'Subungual hemorrhage': 122,\n",
       " 'Telangiectasia': 123,\n",
       " 'Tinea capitis': 124,\n",
       " 'Tinea corporis': 125,\n",
       " 'Tinea cruris': 126,\n",
       " 'Tinea faciale': 127,\n",
       " 'Tinea manus': 128,\n",
       " 'Tinea pedis': 129,\n",
       " 'Toxic epidermal necrolysis': 130,\n",
       " 'Trichotillomania': 131,\n",
       " 'Ulcer': 132,\n",
       " 'Urticaria': 133,\n",
       " 'Urticaria pigmentosa': 134,\n",
       " 'Vascular malformation': 135,\n",
       " 'Verruca plana': 136,\n",
       " 'Viral exanthem': 137,\n",
       " 'Vitiligo': 138,\n",
       " 'Wart': 139,\n",
       " 'Congenital smooth muscle hamartoma': 140,\n",
       " 'Miliaria': 141}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_index = {}\n",
    "for idx, key in zip(range(len(train_dict)), train_dict.keys()):\n",
    "    label_to_index[key] = idx\n",
    "    \n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_skin_data(files):\n",
    "    \n",
    "    for file in files:\n",
    "    \n",
    "        f = file.decode('utf-8')\n",
    "        \n",
    "        img = cv2.imread(f, cv2.COLOR_BGR2YCR_CB)\n",
    "        img = cv2.resize(img, (N_BEF_RES, N_BEF_RES))\n",
    "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        idx = f.split('\\\\')[1].split('/')[2]\n",
    "        lbl = tf.keras.utils.to_categorical(label_to_index[idx], len(train_dict))\n",
    "\n",
    "        yield (img, lbl)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_skin_data(files):\n",
    "    \n",
    "    for file in files:\n",
    "    \n",
    "        f = file.decode('utf-8')\n",
    "        \n",
    "        img = cv2.imread(f, cv2.COLOR_BGR2YCR_CB)\n",
    "        img = cv2.resize(img, (N_BEF_RES, N_BEF_RES))\n",
    "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        \n",
    "        lbl = tf.keras.utils.to_categorical(label_to_index[f.split('\\\\')[1].split('/')[2]], len(train_dict))\n",
    "\n",
    "        yield (img, lbl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57558/57558 [1:11:57<00:00, 13.33it/s] \n"
     ]
    }
   ],
   "source": [
    "# to adapt dataset to model \n",
    "from tqdm import tqdm\n",
    "train = [] \n",
    "\n",
    "for f in tqdm(train_images): \n",
    "    # print(f)\n",
    "    img = cv2.imread(f, cv2.COLOR_BGR2YCR_CB)\n",
    "    img = cv2.resize(img, (N_BEF_RES, N_BEF_RES))\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    train.append(img) \n",
    "    \n",
    "x_train = tf.reshape(train, [-1, N_RES, N_RES, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.02),\n",
    "        layers.RandomWidth(0.2),\n",
    "        layers.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 256, 256, 3)       7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_encoder():\n",
    "    resnet = keras.applications.ResNet50V2(\n",
    "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
    "    )\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = resnet(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 265\n",
    "hidden_units = 512\n",
    "projection_units = 128\n",
    "num_epochs = 50\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "    \n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(N_CLASSES, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(train_skin_data, \n",
    "                                               output_types=(tf.float64, tf.float32), \n",
    "                                               output_shapes=(tf.TensorShape([N_BEF_RES, N_BEF_RES, 3]), tf.TensorShape([N_CLASSES])),\n",
    "                                               args=[train_images])\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(test_skin_data, \n",
    "                                              output_types=(tf.float64, tf.float32), \n",
    "                                              output_shapes=(tf.TensorShape([N_BEF_RES, N_BEF_RES, 3]), tf.TensorShape([N_CLASSES])),\n",
    "                                              args=[test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(len(train_images) * 0.2)\n",
    "split_train_dataset = train_dataset.skip(split_size)\n",
    "split_val_dataset = train_dataset.take(split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_dataset = split_train_dataset.shuffle(150).batch(32, drop_remainder=True).prefetch(AUTOTUNE)\n",
    "split_val_dataset = split_val_dataset.shuffle(150).batch(32, drop_remainder=True).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             23564807  \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 142)               72846     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,686,741\n",
      "Trainable params: 24,641,294\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "classifier = create_classifier(encoder)\n",
    "classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/cifar10-encoder/resnet50v2/post_relu/ReluGrad' defined at (most recent call last):\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\krsty\\AppData\\Local\\Temp/ipykernel_26232/2566592970.py\", line 2, in <module>\n      hist = classifier.fit(split_train_dataset,\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/cifar10-encoder/resnet50v2/post_relu/ReluGrad'\nInputs to operation gradient_tape/model/cifar10-encoder/resnet50v2/post_relu/ReluGrad of type ReluGrad must have the same size and shape.  Input 0: [32,2048,8,8] != input 1: [32,2048,8,9]\n\t [[{{node gradient_tape/model/cifar10-encoder/resnet50v2/post_relu/ReluGrad}}]] [Op:__inference_train_function_33760]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26232/2566592970.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     hist = classifier.fit(split_train_dataset, \n\u001b[0m\u001b[0;32m      3\u001b[0m                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                           validation_data=split_val_dataset)\n",
      "\u001b[1;32mc:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/cifar10-encoder/resnet50v2/post_relu/ReluGrad' defined at (most recent call last):\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\krsty\\AppData\\Local\\Temp/ipykernel_26232/2566592970.py\", line 2, in <module>\n      hist = classifier.fit(split_train_dataset,\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 863, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"c:\\Users\\krsty\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/cifar10-encoder/resnet50v2/post_relu/ReluGrad'\nInputs to operation gradient_tape/model/cifar10-encoder/resnet50v2/post_relu/ReluGrad of type ReluGrad must have the same size and shape.  Input 0: [32,2048,8,8] != input 1: [32,2048,8,9]\n\t [[{{node gradient_tape/model/cifar10-encoder/resnet50v2/post_relu/ReluGrad}}]] [Op:__inference_train_function_33760]"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    hist = classifier.fit(split_train_dataset, \n",
    "                          batch_size=batch_size,  \n",
    "                          epochs=num_epochs, \n",
    "                          validation_data=split_val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = classifier.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "972d6013027de88475209f8403b8f25f5a20015c64576ec1e3cc2c58ecf8fcfb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
